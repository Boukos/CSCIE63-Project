{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\cygwin64\\home\\mpatnam\\CSCIE63\\Project\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###### README ######\n",
    "### Data Columns ###\n",
    "# col1 Date\n",
    "# col2 Open\n",
    "# col3 High\n",
    "# col4 Low\n",
    "# col5 Close\n",
    "# col6 Volume\n",
    "# col7 Adj Close     (X)\n",
    "# col8 Aggr Score1   (Y)\n",
    "# col9 Aggr Score2\n",
    "\n",
    "# try two models #\n",
    "# Predict Sentiment Score (Y) using Close Price (X)\n",
    "# Predict Close Price (Y) using Sentiment Score (X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total samples: 42\n",
      "\n",
      "number of train samples: 33\n",
      "Train sample: [  4.27950000e+04   1.37889999e+02   1.40149994e+02   1.37600006e+02\n",
      "   1.39789993e+02   3.64146000e+07   1.39789993e+02  -5.00000000e-01\n",
      "  -5.00000000e-02]\n",
      "\n",
      "number of test samples: 9\n",
      "Test sample: [  4.28430000e+04   1.41410004e+02   1.42039993e+02   1.41110001e+02\n",
      "   1.41199997e+02   1.46608000e+07   1.41199997e+02   2.00000000e-01\n",
      "   8.00000000e-02]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import xlrd\n",
    "\n",
    "DATA_FILE = 'ClosePrices2.xlsx'\n",
    "\n",
    "\n",
    "\n",
    "# Step 1: read in data from the .xls file\n",
    "book = xlrd.open_workbook(DATA_FILE, encoding_override=\"utf-8\")\n",
    "sheet = book.sheet_by_index(0)\n",
    "n_samples = sheet.nrows - 1\n",
    "print('total samples: {0}'.format(n_samples))\n",
    "\n",
    "# Step 2: use 80% of data for training, remaining for test.\n",
    "train_samples = int(0.8*n_samples)\n",
    "train_data = np.asarray([sheet.row_values(i) for i in range(1, train_samples)])\n",
    "test_samples = n_samples - train_samples\n",
    "test_data = np.asarray([sheet.row_values(i) for i in range(train_samples+1, n_samples)])\n",
    "\n",
    "# train samples\n",
    "print('\\nnumber of train samples: {0}'.format(train_samples))\n",
    "print('Train sample: {0}'.format(train_data[0]))\n",
    "\n",
    "# test samples\n",
    "print('\\nnumber of test samples: {0}'.format(test_samples))\n",
    "print('Test sample: {0}'.format(test_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"X_9:0\", shape=(1, 1), dtype=float32)\n",
      "Tensor(\"Y_9:0\", dtype=float32)\n",
      "Tensor(\"weights_1_2/read:0\", shape=(), dtype=float32)\n",
      "Tensor(\"bias_5/read:0\", shape=(), dtype=float32)\n",
      "Tensor(\"add_4:0\", shape=(1, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Step 3: create placeholders for input Y (Aggregate Sentiment Score) and label X (Close Price)\n",
    "X = tf.placeholder(tf.float32, [1, 1], name='X')\n",
    "Y = tf.placeholder(tf.float32, name='Y')\n",
    "\n",
    "print(X)\n",
    "print(Y)\n",
    "\n",
    "# Step 4: create weight and bias, initialized to 0\n",
    "w = tf.Variable(0.0, name='weights_1')\n",
    "b = tf.Variable(0.0, name='bias')\n",
    "\n",
    "print(w)\n",
    "print(b)\n",
    "\n",
    "# Step 5: build model to predict Y\n",
    "##Y_predicted = tf.matmul(X, w) + b\n",
    "Y_predicted = (X * w) + b \n",
    "print(Y_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Step 6: use the square error as the loss function\n",
    "loss = tf.square(Y - Y_predicted, name='loss')\n",
    "\n",
    "# Step 7: using gradient descent with learning rate of 0.00001 to minimize loss\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.00000001).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Loss epoch 0: [[ 0.25361651]]\n",
      "Average Loss epoch 1: [[ 0.25269467]]\n",
      "Average Loss epoch 2: [[ 0.2517961]]\n",
      "Average Loss epoch 3: [[ 0.25092018]]\n",
      "Average Loss epoch 4: [[ 0.25006643]]\n",
      "Average Loss epoch 5: [[ 0.24923424]]\n",
      "Average Loss epoch 6: [[ 0.24842307]]\n",
      "Average Loss epoch 7: [[ 0.24763238]]\n",
      "Average Loss epoch 8: [[ 0.24686173]]\n",
      "Average Loss epoch 9: [[ 0.24611048]]\n",
      "Average Loss epoch 10: [[ 0.24537823]]\n",
      "Average Loss epoch 11: [[ 0.24466446]]\n",
      "Average Loss epoch 12: [[ 0.24396871]]\n",
      "Average Loss epoch 13: [[ 0.24329056]]\n",
      "Average Loss epoch 14: [[ 0.2426295]]\n",
      "Average Loss epoch 15: [[ 0.24198523]]\n",
      "Average Loss epoch 16: [[ 0.24135716]]\n",
      "Average Loss epoch 17: [[ 0.24074498]]\n",
      "Average Loss epoch 18: [[ 0.24014828]]\n",
      "Average Loss epoch 19: [[ 0.23956662]]\n",
      "Average Loss epoch 20: [[ 0.23899966]]\n",
      "Average Loss epoch 21: [[ 0.23844707]]\n",
      "Average Loss epoch 22: [[ 0.23790844]]\n",
      "Average Loss epoch 23: [[ 0.23738334]]\n",
      "Average Loss epoch 24: [[ 0.23687159]]\n",
      "Average Loss epoch 25: [[ 0.23637272]]\n",
      "Average Loss epoch 26: [[ 0.23588641]]\n",
      "Average Loss epoch 27: [[ 0.23541248]]\n",
      "Average Loss epoch 28: [[ 0.23495051]]\n",
      "Average Loss epoch 29: [[ 0.23450018]]\n",
      "Average Loss epoch 30: [[ 0.2340612]]\n",
      "Average Loss epoch 31: [[ 0.23363331]]\n",
      "Average Loss epoch 32: [[ 0.23321629]]\n",
      "Average Loss epoch 33: [[ 0.23280984]]\n",
      "Average Loss epoch 34: [[ 0.2324136]]\n",
      "Average Loss epoch 35: [[ 0.2320274]]\n",
      "Average Loss epoch 36: [[ 0.2316509]]\n",
      "Average Loss epoch 37: [[ 0.23128396]]\n",
      "Average Loss epoch 38: [[ 0.23092631]]\n",
      "Average Loss epoch 39: [[ 0.23057765]]\n",
      "Average Loss epoch 40: [[ 0.23023783]]\n",
      "Average Loss epoch 41: [[ 0.22990659]]\n",
      "Average Loss epoch 42: [[ 0.2295837]]\n",
      "Average Loss epoch 43: [[ 0.229269]]\n",
      "Average Loss epoch 44: [[ 0.22896226]]\n",
      "Average Loss epoch 45: [[ 0.22866324]]\n",
      "Average Loss epoch 46: [[ 0.22837178]]\n",
      "Average Loss epoch 47: [[ 0.22808769]]\n",
      "Average Loss epoch 48: [[ 0.22781079]]\n",
      "Average Loss epoch 49: [[ 0.22754093]]\n",
      "Average Loss epoch 50: [[ 0.22727783]]\n",
      "Average Loss epoch 51: [[ 0.2270214]]\n",
      "Average Loss epoch 52: [[ 0.22677143]]\n",
      "Average Loss epoch 53: [[ 0.22652782]]\n",
      "Average Loss epoch 54: [[ 0.22629032]]\n",
      "Average Loss epoch 55: [[ 0.22605884]]\n",
      "Average Loss epoch 56: [[ 0.22583324]]\n",
      "Average Loss epoch 57: [[ 0.2256133]]\n",
      "Average Loss epoch 58: [[ 0.22539894]]\n",
      "Average Loss epoch 59: [[ 0.22519004]]\n",
      "Average Loss epoch 60: [[ 0.22498633]]\n",
      "Average Loss epoch 61: [[ 0.22478788]]\n",
      "Average Loss epoch 62: [[ 0.22459434]]\n",
      "Average Loss epoch 63: [[ 0.22440577]]\n",
      "Average Loss epoch 64: [[ 0.22422189]]\n",
      "Average Loss epoch 65: [[ 0.22404273]]\n",
      "Average Loss epoch 66: [[ 0.2238681]]\n",
      "Average Loss epoch 67: [[ 0.22369789]]\n",
      "Average Loss epoch 68: [[ 0.22353193]]\n",
      "Average Loss epoch 69: [[ 0.22337021]]\n",
      "Average Loss epoch 70: [[ 0.22321254]]\n",
      "Average Loss epoch 71: [[ 0.22305879]]\n",
      "Average Loss epoch 72: [[ 0.22290911]]\n",
      "Average Loss epoch 73: [[ 0.22276306]]\n",
      "Average Loss epoch 74: [[ 0.22262074]]\n",
      "Average Loss epoch 75: [[ 0.22248209]]\n",
      "Average Loss epoch 76: [[ 0.22234692]]\n",
      "Average Loss epoch 77: [[ 0.2222151]]\n",
      "Average Loss epoch 78: [[ 0.22208664]]\n",
      "Average Loss epoch 79: [[ 0.2219615]]\n",
      "Average Loss epoch 80: [[ 0.22183946]]\n",
      "Average Loss epoch 81: [[ 0.22172053]]\n",
      "Average Loss epoch 82: [[ 0.2216046]]\n",
      "Average Loss epoch 83: [[ 0.22149161]]\n",
      "Average Loss epoch 84: [[ 0.22138146]]\n",
      "Average Loss epoch 85: [[ 0.22127408]]\n",
      "Average Loss epoch 86: [[ 0.22116944]]\n",
      "Average Loss epoch 87: [[ 0.22106743]]\n",
      "Average Loss epoch 88: [[ 0.22096802]]\n",
      "Average Loss epoch 89: [[ 0.22087114]]\n",
      "Average Loss epoch 90: [[ 0.22077669]]\n",
      "Average Loss epoch 91: [[ 0.22068465]]\n",
      "Average Loss epoch 92: [[ 0.22059493]]\n",
      "Average Loss epoch 93: [[ 0.22050741]]\n",
      "Average Loss epoch 94: [[ 0.22042218]]\n",
      "Average Loss epoch 95: [[ 0.22033909]]\n",
      "Average Loss epoch 96: [[ 0.2202581]]\n",
      "Average Loss epoch 97: [[ 0.2201792]]\n",
      "Average Loss epoch 98: [[ 0.22010224]]\n",
      "Average Loss epoch 99: [[ 0.22002722]]\n"
     ]
    }
   ],
   "source": [
    "train_times=100  # train the model 100 times\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Step 7: initialize the necessary variables, in this case, w and b\n",
    "    sess.run(tf.global_variables_initializer()) \n",
    "    writer = tf.summary.FileWriter('C:/code/tensorflow/output/proj.regression2', sess.graph)\n",
    "    \n",
    "    # Step 8: train the model\n",
    "    for i in range(train_times):\n",
    "        total_loss = 0\n",
    "        # y: SentimentScore\n",
    "        # x: ClosePrice\n",
    "        #flip x and y below to run second model\n",
    "        for n, _, _, _, _, _, x, y, _ in train_data:\n",
    "            # Session runs train_op and fetch values of loss\n",
    "            #print('n:{0}, x:{1}, y:{2}'.format(n, x, y))\n",
    "            _, l = sess.run([optimizer, loss], feed_dict={X: np.reshape([x], (1,1)) , Y:y }) \n",
    "            total_loss += l\n",
    "        print('Average Loss epoch {0}: {1}'.format(i, total_loss/n_samples))\n",
    "\n",
    "    # close the writer when you're done using it\n",
    "    writer.close() \n",
    "\n",
    "    # Step 9: output the values of w and b\n",
    "    w_value, b_value = sess.run([w, b]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights:0.0011255745775997639\n",
      "Bias: 0.00001\n",
      "Test Close Prices: [ 141.199997  140.679993  142.440002  142.270004  143.639999  144.529999\n",
      "  143.679993  143.789993]\n",
      "Test sample: [  4.28430000e+04   1.41410004e+02   1.42039993e+02   1.41110001e+02\n",
      "   1.41199997e+02   1.46608000e+07   1.41199997e+02   2.00000000e-01\n",
      "   8.00000000e-02]\n",
      "Predicted Sentiment Score using test data:[ 0.15893894  0.15835364  0.16033466  0.16014332  0.16168535  0.16268711\n",
      "  0.16173036  0.16185418]\n",
      "Actual Sentiment Score:[ 0.2   0.   -0.1   0.8   0.9   0.1  -0.41  0.51]\n",
      "Model accuracy using RMSE:  0.433167392451\n"
     ]
    }
   ],
   "source": [
    "# calculate squared value (for RMSE purpose) given a predicted and actual value\n",
    "def squared_error(pred, actual):\n",
    "    return (pred - actual) ** 2\n",
    "\n",
    "# Step 8: report results\n",
    "print('Weights:{0}'.format(w_value))\n",
    "print('Bias: %2.5f' % b_value)\n",
    "\n",
    "#access test columns\n",
    "#flip indices to run second model\n",
    "X, Y = test_data.T[6], test_data.T[7]\n",
    "print('Test Close Prices: {0}'.format(X))\n",
    "print('Test sample: {0}'.format(test_data[0]))\n",
    "Y_predicted_test = X * w_value + b_value\n",
    "print('Predicted Sentiment Score using test data:{0}'.format(Y_predicted_test))\n",
    "print('Actual Sentiment Score:{0}'.format(Y))\n",
    "\n",
    "# measure RMSE accuracy\n",
    "accuracy_rmse = np.sqrt(squared_error(Y_predicted_test, Y).mean())\n",
    "print('Model accuracy using RMSE: ', accuracy_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAD8CAYAAABthzNFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/wFxO9bh88pzNAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x28a8ef69860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the results\n",
    "X, Y = train_data.T[6], train_data.T[7]\n",
    "plt.plot(X, Y, 'bo', label='Real data')\n",
    "plt.plot(X, (X * w_value) + b_value, 'ro', label='Predicted data')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
